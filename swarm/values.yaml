# Default values for swarm.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

swarm:
  # Metrics: If enabled it will deploy a InfluxDB + Grafana stack.
  # All swarm nodes will forward metrics to the deploy InfluxDB instance
  metricsEnabled: true
  # Tracing: If enabled, jaeger instance will be deployed.
  tracingEnabled: false
  # Profiling: Enable PPROF
  profilingEnabled: false
  # Image configuration
  image:
    repository: ethdevops/swarm
    tag: latest
  ## Specify a imagePullPolicy
  ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
  ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
  ##
  imagePullPolicy: Always
  ## (dict) If specified, apply these annotations to the swarm pods
  # podAnnotations:
  #   fluentbit.io/exclude: "true"
  # How many swarm nodes we want to run
  replicaCount: 2
  # Pod management policy
  # https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  podManagementPolicy: OrderedReady  # Choose between "OrderedReady" or "Parallel"
  # Update strategy:
  # https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  updateStrategy:
    type: "RollingUpdate"
   # Duration in seconds the pod needs to terminate gracefully
  terminationGracePeriodSeconds: 30
  config:
    # ENS API endpoint
    ens_api: http://geth-host:8545
    # Logging verbosity: 0=silent, 1=error, 2=warn, 3=info, 4=debug, 5=detail
    verbosity: 3
    # Prepends log messages with call-site location (file and line number)
    debug: false
    # Maximum number of network peers (network disabled if set to 0)
    maxpeers: 25
    # Network identifier (integer, default 3=swarm testnet)
    bzznetworkid: 3
    # LevelDB Store size - by default 4kb * 10^5 == 400 megabytes
    storesize: 100000
    # List of bootnodes. Example configuration:
    #bootnodes:
    # - enode://xxxxxx@10.0.1.5:30301
    # - enode://yyyyyy@10.0.1.7:30301
    bootnodes: []
    extraFlags: []

  secrets:
     # Used to setup a sample Ethereum account in the data directory.
     # If a data directory is mounted with a volume, the first Ethereum account from it
     # is loaded, and Swarm will try to decrypt it non-interactively with this password.
    password: qwerty

  persistence:
    ## this enables PVC templates that will create one per pod
    enabled: false
    ## swarm data Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    # storageClass: "-"
    accessMode: ReadWriteOnce
    size: 8Gi

  ## Configure resource requests and limits
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  resources:
    requests:
      memory: 256Mi
      cpu: 0.1
    limits:
      memory: 1024Mi
      cpu: 0.3
  ## Node labels and tolerations for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#taints-and-tolerations-beta-feature
  nodeSelector: {}
  tolerations: []
  affinity: {}

  ingress:
    enabled: true
    tls:
      enabled: false
      acmeEnabled: false # Use cert-manager to generate certificates via ACME
    domain: default.swarm-gateways.net
    annotations:
      nginx.ingress.kubernetes.io/proxy-body-size: 20m

jaeger:
  image:
    repository: jaegertracing/all-in-one
    tag: 1.7.0
  ## Specify a imagePullPolicy
  ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
  ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
  ##
  imagePullPolicy: IfNotPresent
  replicaCount: 1
  service:
    query:
      type: ClusterIP
    agent:
      type: ClusterIP
  ## Configure resource requests and limits
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  resources: {}
  ## Node labels and tolerations for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#taints-and-tolerations-beta-feature
  nodeSelector: {}
  tolerations: []
  affinity: {}


##
## Influxdb Dependency
##

influxdb:
  ## influxdb image version
  ## ref: https://hub.docker.com/r/library/influxdb/tags/
  image:
    repo: "influxdb"
    tag: "1.7.4"
    pullPolicy: IfNotPresent

  ## Specify a service type
  ## ref: http://kubernetes.io/docs/user-guide/services/
  ##
  service:
    ## Add annotations to service
    # annotations: {}
    type: ClusterIP
    ## Add IP Cluster
    # clusterIP: ""
    ## Add external IPs that route to one or more cluster nodes
    # externalIPs: []
    ## Specify LoadBalancer IP (only allow on some cloud provider)
    # loadBalancerIP: ""
    ## Allow source IPs to access on service (if empty, any access allow)
    # loadBalancerSourceRanges: []

  ## Persist data to a persistent volume
  ##
  persistence:
    enabled: false
    ## If true will use an existing PVC instead of creating one
    # useExisting: false
    ## Name of existing PVC to be used in the influx deployment
    # name:
    ## influxdb data Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    # storageClass: "-"
    accessMode: ReadWriteOnce
    size: 8Gi

  ## Create default user through Kubernetes job
  ## Defaults indicated below
  ##
  setDefaultUser:
    enabled: true

    ## Image of the container used for job
    ## Default: appropriate/curl:latest
    ##
    image: appropriate/curl:latest

    ## Deadline for job so it does not retry forever.
    ## Default: activeDeadline: 300
    ##
    activeDeadline: 300

    ## Restart policy for job
    ## Default: OnFailure
    restartPolicy: OnFailure

    user:

      ## The user name
      ## Default: "admin"
      username: "swarm"

      ## User password
      ## single quotes must be escaped (\')
      ## Default:
      password: "swarm"

      ## User privileges
      ## Default: "WITH ALL PRIVILEGES"
      privileges: "WITH ALL PRIVILEGES"

  ## Configure resource requests and limits
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  resources:
    requests:
      memory: 256Mi
      cpu: 0.1
    limits:
      memory: 16Gi
      cpu: 8

  ingress:
    enabled: false
    # Warning: Exposing the websocket RPC API can be dangerous.
    #          This should be used only for testing purposes.
    exposeWebsocketRPC: false
    tls: false
    # secretName: my-tls-cert # only needed if tls above is true
    hostname: influxdb.foobar.com
    annotations:
      # kubernetes.io/ingress.class: "nginx"
      # kubernetes.io/tls-acme: "true"

  ## Use an alternate scheduler, e.g. "stork".
  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  # schedulerName:

  ## Node labels for pod assignment
  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}

  ## The InfluxDB image uses several environment variables to automatically
  ## configure certain parts of the server.
  ## Ref: https://hub.docker.com/_/influxdb/
  env:
  - name: INFLUXDB_DB
    value: "metrics"
  - name: INFLUXDB_LOGGING_LEVEL
    value: "warn"
  ## Change InfluxDB configuration parameters below:
  ## Defaults are indicated
  ## ref: https://docs.influxdata.com/influxdb/v1.1/administration/config/
  config:
    reporting_disabled: false
    bind_address: 8088
    storage_directory: /var/lib/influxdb
    meta:
      retention_autocreate: true
      logging_enabled: true
    data:
      query_log_enabled: false
      cache_max_memory_size: 1073741824
      cache_snapshot_memory_size: 26214400
      cache_snapshot_write_cold_duration: 10m0s
      compact_full_write_cold_duration: 4h0m0s
      max_series_per_database: 1000000
      max_values_per_tag: 100000
      trace_logging_enabled: false
    coordinator:
      write_timeout: 10s
      max_concurrent_queries: 0
      query_timeout: 0s
      log_queries_after: 0s
      max_select_point: 0
      max_select_series: 0
      max_select_buckets: 0
    retention:
      enabled: true
      check_interval: 30m0s
    shard_precreation:
      enabled: true
      check_interval: 10m0s
      advance_period: 30m0s
    admin:
      enabled: false
      bind_address: 8083
      https_enabled: false
      https_certificate: /etc/ssl/influxdb.pem
    monitor:
      store_enabled: true
      store_database: _internal
      store_interval: 10s
    subscriber:
      enabled: true
      http_timeout: 30s
      insecure_skip_verify: false
      ca_certs: ""
      write_concurrency: 40
      write_buffer_size: 1000
    http:
      enabled: true
      bind_address: 8086
      auth_enabled: false
      log_enabled: false
      write_tracing: false
      pprof_enabled: true
      https_enabled: false
      https_certificate: /etc/ssl/influxdb.pem
      https_private_key: ""
      max_row_limit: 10000
      max_connection_limit: 0
      shared_secret: "beetlejuicebeetlejuicebeetlejuice"
      realm: InfluxDB
      unix_socket_enabled: false
      bind_socket: /var/run/influxdb.sock
    graphite:
      enabled: false
      bind_address: 2003
      database: graphite
      retention_policy: autogen
      protocol: tcp
      batch_size: 5000
      batch_pending: 10
      batch_timeout: 1s
      consistency_level: one
      separator: .
      udp_read_buffer: 0
      # Uncomment to define graphite templates
      # templates:
      #   - "graphite.metric.*.*.* measurement.run"
    collectd:
      enabled: false
      bind_address: 25826
      database: collectd
      retention_policy: autogen
      batch_size: 5000
      batch_pending: 10
      batch_timeout: 10s
      read_buffer: 0
      typesdb: /usr/share/collectd/types.db
      security_level: none
      auth_file: /etc/collectd/auth_file
    opentsdb:
      enabled: false
      bind_address: 4242
      database: opentsdb
      retention_policy: autogen
      consistency_level: one
      tls_enabled: false
      certificate: /etc/ssl/influxdb.pem
      batch_size: 1000
      batch_pending: 5
      batch_timeout: 1s
      log_point_errors: true
    udp:
      enabled: false
      bind_address: 8089
      database: udp
      retention_policy: autogen
      batch_size: 5000
      batch_pending: 10
      read_buffer: 0
      batch_timeout: 1s
      precision: "ns"
    continuous_queries:
      log_enabled: true
      enabled: true
      run_interval: 1s



##
## Grafana dependency
##
grafana:
  rbac:
    create: false
    pspEnabled: false
  serviceAccount:
    create: true
    name:

  replicas: 1

  deploymentStrategy: RollingUpdate

  image:
    repository: grafana/grafana
    tag: 5.2.4
    pullPolicy: IfNotPresent

    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ##
    # pullSecrets:
    #   - myRegistrKeySecretName

  securityContext:
    runAsUser: 472
    fsGroup: 472

  downloadDashboardsImage:
    repository: appropriate/curl
    tag: latest
    pullPolicy: IfNotPresent

  ## Pod Annotations
  # podAnnotations: {}

  ## Deployment annotations
  # annotations: {}

  ## Expose the grafana service to be accessed from outside the cluster (LoadBalancer service).
  ## or access it from within the cluster (ClusterIP service). Set the service type and the port to serve it.
  ## ref: http://kubernetes.io/docs/user-guide/services/
  ##
  service:
    type: ClusterIP
    port: 80
    annotations: {}
    labels: {}

  ingress:
    enabled: false
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    labels: {}
    path: /
    hosts:
      - chart-example.local
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  resources: {}
  #  limits:
  #    cpu: 100m
  #    memory: 128Mi
  #  requests:
  #    cpu: 100m
  #    memory: 128Mi

  ## Node labels for pod assignment
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  #
  nodeSelector: {}

  ## Tolerations for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []

  ## Affinity for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ##
  affinity: {}

  ## Enable persistence using Persistent Volume Claims
  ## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
  ##
  persistence:
    enabled: false
    # storageClassName: default
    # accessModes:
    #   - ReadWriteOnce
    # size: 10Gi
    # annotations: {}
    # subPath: ""
    # existingClaim:

  adminUser: swarm
  adminPassword: swarm

  ## Use an alternate scheduler, e.g. "stork".
  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  # schedulerName:

  ## Extra environment variables that will be pass onto deployment pods
  env: {}

  ## The name of a secret in the same kubernetes namespace which contain values to be added to the environment
  ## This can be useful for auth tokens, etc
  envFromSecret: ""

  ## Additional grafana server secret mounts
  # Defines additional mounts with secrets. Secrets must be manually created in the namespace.
  extraSecretMounts: []
    # - name: secret-files
    #   mountPath: /etc/secrets
    #   secretName: grafana-secret-files
    #   readOnly: true

  ## Pass the plugins you want installed as a list.
  ##
  plugins: []
    # - digrich-bubblechart-panel
    # - grafana-clock-panel

  ## Configure grafana datasources
  ## ref: http://docs.grafana.org/administration/provisioning/#datasources
  ##
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
      - name: metrics
        type: influxdb
        url: http://swarm-influxdb:8086
        database: metrics
        user: swarm
        password: swarm
        access: proxy
        isDefault: true

  ## Configure grafana dashboard providers
  ## ref: http://docs.grafana.org/administration/provisioning/#dashboards
  ##
  ## `path` must be /var/lib/grafana/dashboards/<provider_name>
  ##
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
      - name: 'default'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        editable: true
        options:
          path: /var/lib/grafana/dashboards/default

  ## Configure grafana dashboard to import
  ## NOTE: To use dashboards you must also enable/configure dashboardProviders
  ## ref: https://grafana.com/dashboards
  ##
  ## dashboards per provider, use provider name as key.
  ##
  dashboards:
    default:
      smoke:
        url: https://raw.githubusercontent.com/ethersphere/grafana-dashboards/master/smoke.json
      ldbstore:
        url: https://raw.githubusercontent.com/ethersphere/grafana-dashboards/master/ldbstore.json
      swarm:
        url: https://raw.githubusercontent.com/ethersphere/grafana-dashboards/master/swarm.json
      upload-speed:
        url: https://raw.githubusercontent.com/ethersphere/grafana-dashboards/master/upload-speed.json

  ## Reference to external ConfigMap per provider. Use provider name as key and ConfiMap name as value.
  ## A provider dashboards must be defined either by external ConfigMaps or in values.yaml, not in both.
  ## ConfigMap data example:
  ##
  ## data:
  ##   example-dashboard.json: |
  ##     RAW_JSON
  ##
  dashboardsConfigMaps: {}
  #  default: ""

  ## Grafana's primary configuration
  ## NOTE: values in map will be converted to ini format
  ## ref: http://docs.grafana.org/installation/configuration/
  ##
  grafana.ini:
    paths:
      data: /var/lib/grafana/data
      logs: /var/log/grafana
      plugins: /var/lib/grafana/plugins
      provisioning: /etc/grafana/provisioning
    analytics:
      check_for_updates: false
    log:
      mode: console
    grafana_net:
      url: https://grafana.net
    auth.anonymous:
      enabled: true

  ## LDAP Authentication can be enabled with the following values on grafana.ini
  ## NOTE: Grafana will fail to start if the value for ldap.toml is invalid
    # auth.ldap:
    #   enabled: true
    #   allow_sign_up: true
    #   config_file: /etc/grafana/ldap.toml

  ## Grafana's LDAP configuration
  ## Templated by the template in _helpers.tpl
  ## NOTE: To enable the grafana.ini must be configured with auth.ldap.enabled
  ## ref: http://docs.grafana.org/installation/configuration/#auth-ldap
  ## ref: http://docs.grafana.org/installation/ldap/#configuration
  ldap:
    # `existingSecret` is a reference to an existing secret containing the ldap configuration
    # for Grafana in a key `ldap-toml`.
    existingSecret: ""
    # `config` is the content of `ldap.toml` that will be stored in the created secret
    config: ""
    # config: |-
    #   verbose_logging = true

    #   [[servers]]
    #   host = "my-ldap-server"
    #   port = 636
    #   use_ssl = true
    #   start_tls = false
    #   ssl_skip_verify = false
    #   bind_dn = "uid=%s,ou=users,dc=myorg,dc=com"

  ## Grafana's SMTP configuration
  ## NOTE: To enable, grafana.ini must be configured with smtp.enabled
  ## ref: http://docs.grafana.org/installation/configuration/#smtp
  smtp:
    # `existingSecret` is a reference to an existing secret containing the smtp configuration
    # for Grafana in keys `user` and `password`.
    existingSecret: ""

  ## Sidecars that collect the configmaps with specified label and stores the included files them into the respective folders
  ## Requires at least Grafana 5 to work and can't be used together with parameters dashboardProviders, datasources and dashboards
  sidecar:
    image: kiwigrid/k8s-sidecar:0.0.3
    imagePullPolicy: IfNotPresent
    resources:
  #   limits:
  #     cpu: 100m
  #     memory: 100Mi
  #   requests:
  #     cpu: 50m
  #     memory: 50Mi
    dashboards:
      enabled: false
      # label that the configmaps with dashboards are marked with
      label: grafana_dashboard
      # folder in the pod that should hold the collected dashboards
      folder: /tmp/dashboards
    datasources:
      enabled: false
      # label that the configmaps with datasources are marked with
      label: grafana_datasource
